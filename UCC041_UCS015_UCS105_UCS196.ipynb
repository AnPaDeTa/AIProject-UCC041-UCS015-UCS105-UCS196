{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UCC041-UCS015-UCS105-UCS196.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do-Ssu_OxyKw"
      },
      "source": [
        "# Importing the required classes and libraries\n",
        "from itertools import islice, chain\n",
        "import pandas as pd\n",
        "import nltk"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCI6K5t4Iaqc"
      },
      "source": [
        "def get_index_positions(list_of_elems, element):\n",
        "  ''' Returns the indices of all occurrences of given element in\n",
        "  the list- list_of_elems '''\n",
        "  index_pos_list = []\n",
        "  index_pos = 0\n",
        "  while True:\n",
        "    try:\n",
        "      # Search for item in list from index_pos to the end of list\n",
        "      index_pos = list_of_elems.index(element, index_pos)\n",
        "      # Add the index position in list\n",
        "      index_pos_list.append(index_pos)\n",
        "      index_pos += 1\n",
        "    except ValueError:\n",
        "      break\n",
        "  return index_pos_list"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np64a_c1-KhH"
      },
      "source": [
        "def convert_list_1dto2d(list_of_elems, list_of_lengths): \n",
        "  ''' Returns a 2-dimensional list of given variable lengths-\n",
        "  list_of_lengths from the 1-dimensional list- list_of_elems '''\n",
        "  # Generate an iterator of the 1-d list\n",
        "  iterator = iter(list_of_elems)\n",
        "  # Slice the 1-d list in variable lengths and add it to a 2-d list\n",
        "  return [list(islice(iterator, i)) for i in list_of_lengths]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3JlDgmQjNOC"
      },
      "source": [
        "def preprocess_dataset(filename):\n",
        "  ''' Return the preprocessed dataset from the dataset- filename\n",
        "  in  the format of a 2-d list of sentences with each sentence being\n",
        "  a list of tuples- (word, tag) '''\n",
        "  sentences = []\n",
        "  try:\n",
        "    with open(filename) as f:\n",
        "      for line in f:\n",
        "        # Read each line in the file\n",
        "        sentences.append(tuple(word for word in line.split()[:-1]))\n",
        "  except IOError:\n",
        "    print('There is no file named: ', filename)       \n",
        "  # Add ('##', '##') and ('&&', '&&') to mark the beginning and end, respectively, of each sentence    \n",
        "  for index, phrase in enumerate(sentences):\n",
        "    if phrase == ('.', '.'):\n",
        "      # Insert ('&&', '&&') after each ('.', '.')\n",
        "      sentences.insert(index + 1, ('&&', '&&'))\n",
        "    elif phrase == ():\n",
        "      sentences[index] = ('##', '##')\n",
        "  # Append ('##', '##') to the beginning of the first sentence\n",
        "  sentences.insert(0, ('##', '##'))\n",
        "  # Get indices of all occurrences of ('&&','&&')\n",
        "  indices = get_index_positions(sentences, ('&&','&&'))\n",
        "  # Generate the lengths of each sentence in the dataset\n",
        "  length_first_sentence = indices[0]\n",
        "  length_of_sentences = [indices[i + 1] - indices[i] for i in range(len(indices)-1)]\n",
        "  length_of_sentences = [length_first_sentence + 1] + length_of_sentences\n",
        "  # Create a 2-d list of sentences\n",
        "  # eg. [sentence1, sentence2, ...]\n",
        "  sentences = convert_list_1dto2d(sentences, length_of_sentences)\n",
        "  return sentences"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71Dua6lz4InP"
      },
      "source": [
        "training_data_sentences = preprocess_dataset('train.txt')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDjSibv6-9e4",
        "outputId": "a5d8cfef-65bb-4673-b16a-7d7a9730c4c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the first 5 sentences in the preprocessed training dataset\n",
        "training_data_sentences[0:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('##', '##'),\n",
              "  ('Confidence', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('pound', 'NN'),\n",
              "  ('is', 'VBZ'),\n",
              "  ('widely', 'RB'),\n",
              "  ('expected', 'VBN'),\n",
              "  ('to', 'TO'),\n",
              "  ('take', 'VB'),\n",
              "  ('another', 'DT'),\n",
              "  ('sharp', 'JJ'),\n",
              "  ('dive', 'NN'),\n",
              "  ('if', 'IN'),\n",
              "  ('trade', 'NN'),\n",
              "  ('figures', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('September', 'NNP'),\n",
              "  (',', ','),\n",
              "  ('due', 'JJ'),\n",
              "  ('for', 'IN'),\n",
              "  ('release', 'NN'),\n",
              "  ('tomorrow', 'NN'),\n",
              "  (',', ','),\n",
              "  ('fail', 'VB'),\n",
              "  ('to', 'TO'),\n",
              "  ('show', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('substantial', 'JJ'),\n",
              "  ('improvement', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('July', 'NNP'),\n",
              "  ('and', 'CC'),\n",
              "  ('August', 'NNP'),\n",
              "  (\"'s\", 'POS'),\n",
              "  ('near-record', 'JJ'),\n",
              "  ('deficits', 'NNS'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('Chancellor', 'NNP'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('Exchequer', 'NNP'),\n",
              "  ('Nigel', 'NNP'),\n",
              "  ('Lawson', 'NNP'),\n",
              "  (\"'s\", 'POS'),\n",
              "  ('restated', 'VBN'),\n",
              "  ('commitment', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('a', 'DT'),\n",
              "  ('firm', 'NN'),\n",
              "  ('monetary', 'JJ'),\n",
              "  ('policy', 'NN'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('helped', 'VBN'),\n",
              "  ('to', 'TO'),\n",
              "  ('prevent', 'VB'),\n",
              "  ('a', 'DT'),\n",
              "  ('freefall', 'NN'),\n",
              "  ('in', 'IN'),\n",
              "  ('sterling', 'NN'),\n",
              "  ('over', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('past', 'JJ'),\n",
              "  ('week', 'NN'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('But', 'CC'),\n",
              "  ('analysts', 'NNS'),\n",
              "  ('reckon', 'VBP'),\n",
              "  ('underlying', 'VBG'),\n",
              "  ('support', 'NN'),\n",
              "  ('for', 'IN'),\n",
              "  ('sterling', 'NN'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('been', 'VBN'),\n",
              "  ('eroded', 'VBN'),\n",
              "  ('by', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('chancellor', 'NN'),\n",
              "  (\"'s\", 'POS'),\n",
              "  ('failure', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('announce', 'VB'),\n",
              "  ('any', 'DT'),\n",
              "  ('new', 'JJ'),\n",
              "  ('policy', 'NN'),\n",
              "  ('measures', 'NNS'),\n",
              "  ('in', 'IN'),\n",
              "  ('his', 'PRP$'),\n",
              "  ('Mansion', 'NNP'),\n",
              "  ('House', 'NNP'),\n",
              "  ('speech', 'NN'),\n",
              "  ('last', 'JJ'),\n",
              "  ('Thursday', 'NNP'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('This', 'DT'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('increased', 'VBN'),\n",
              "  ('the', 'DT'),\n",
              "  ('risk', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('government', 'NN'),\n",
              "  ('being', 'VBG'),\n",
              "  ('forced', 'VBN'),\n",
              "  ('to', 'TO'),\n",
              "  ('increase', 'VB'),\n",
              "  ('base', 'NN'),\n",
              "  ('rates', 'NNS'),\n",
              "  ('to', 'TO'),\n",
              "  ('16', 'CD'),\n",
              "  ('%', 'NN'),\n",
              "  ('from', 'IN'),\n",
              "  ('their', 'PRP$'),\n",
              "  ('current', 'JJ'),\n",
              "  ('15', 'CD'),\n",
              "  ('%', 'NN'),\n",
              "  ('level', 'NN'),\n",
              "  ('to', 'TO'),\n",
              "  ('defend', 'VB'),\n",
              "  ('the', 'DT'),\n",
              "  ('pound', 'NN'),\n",
              "  (',', ','),\n",
              "  ('economists', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('foreign', 'JJ'),\n",
              "  ('exchange', 'NN'),\n",
              "  ('market', 'NN'),\n",
              "  ('analysts', 'NNS'),\n",
              "  ('say', 'VBP'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('``', '``'),\n",
              "  ('The', 'DT'),\n",
              "  ('risks', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('sterling', 'NN'),\n",
              "  ('of', 'IN'),\n",
              "  ('a', 'DT'),\n",
              "  ('bad', 'JJ'),\n",
              "  ('trade', 'NN'),\n",
              "  ('figure', 'NN'),\n",
              "  ('are', 'VBP'),\n",
              "  ('very', 'RB'),\n",
              "  ('heavily', 'RB'),\n",
              "  ('on', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('down', 'JJ'),\n",
              "  ('side', 'NN'),\n",
              "  (',', ','),\n",
              "  (\"''\", \"''\"),\n",
              "  ('said', 'VBD'),\n",
              "  ('Chris', 'NNP'),\n",
              "  ('Dillow', 'NNP'),\n",
              "  (',', ','),\n",
              "  ('senior', 'JJ'),\n",
              "  ('U.K.', 'NNP'),\n",
              "  ('economist', 'NN'),\n",
              "  ('at', 'IN'),\n",
              "  ('Nomura', 'NNP'),\n",
              "  ('Research', 'NNP'),\n",
              "  ('Institute', 'NNP'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJCvcq6jIA2N"
      },
      "source": [
        "testing_data_sentences  = preprocess_dataset('test.txt')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaxuKt4jItXa",
        "outputId": "be5b81d6-0af1-4fb5-efb5-26d15a1ec34c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the first 5 sentences in the preprocessed testing dataset\n",
        "testing_data_sentences[0:5]"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('##', '##'),\n",
              "  ('Rockwell', 'NNP'),\n",
              "  ('International', 'NNP'),\n",
              "  ('Corp.', 'NNP'),\n",
              "  (\"'s\", 'POS'),\n",
              "  ('Tulsa', 'NNP'),\n",
              "  ('unit', 'NN'),\n",
              "  ('said', 'VBD'),\n",
              "  ('it', 'PRP'),\n",
              "  ('signed', 'VBD'),\n",
              "  ('a', 'DT'),\n",
              "  ('tentative', 'JJ'),\n",
              "  ('agreement', 'NN'),\n",
              "  ('extending', 'VBG'),\n",
              "  ('its', 'PRP$'),\n",
              "  ('contract', 'NN'),\n",
              "  ('with', 'IN'),\n",
              "  ('Boeing', 'NNP'),\n",
              "  ('Co.', 'NNP'),\n",
              "  ('to', 'TO'),\n",
              "  ('provide', 'VB'),\n",
              "  ('structural', 'JJ'),\n",
              "  ('parts', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('Boeing', 'NNP'),\n",
              "  (\"'s\", 'POS'),\n",
              "  ('747', 'CD'),\n",
              "  ('jetliners', 'NNS'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('Rockwell', 'NNP'),\n",
              "  ('said', 'VBD'),\n",
              "  ('the', 'DT'),\n",
              "  ('agreement', 'NN'),\n",
              "  ('calls', 'VBZ'),\n",
              "  ('for', 'IN'),\n",
              "  ('it', 'PRP'),\n",
              "  ('to', 'TO'),\n",
              "  ('supply', 'VB'),\n",
              "  ('200', 'CD'),\n",
              "  ('additional', 'JJ'),\n",
              "  ('so-called', 'JJ'),\n",
              "  ('shipsets', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('planes', 'NNS'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('These', 'DT'),\n",
              "  ('include', 'VBP'),\n",
              "  (',', ','),\n",
              "  ('among', 'IN'),\n",
              "  ('other', 'JJ'),\n",
              "  ('parts', 'NNS'),\n",
              "  (',', ','),\n",
              "  ('each', 'DT'),\n",
              "  ('jetliner', 'NN'),\n",
              "  (\"'s\", 'POS'),\n",
              "  ('two', 'CD'),\n",
              "  ('major', 'JJ'),\n",
              "  ('bulkheads', 'NNS'),\n",
              "  (',', ','),\n",
              "  ('a', 'DT'),\n",
              "  ('pressure', 'NN'),\n",
              "  ('floor', 'NN'),\n",
              "  (',', ','),\n",
              "  ('torque', 'NN'),\n",
              "  ('box', 'NN'),\n",
              "  (',', ','),\n",
              "  ('fixed', 'VBN'),\n",
              "  ('leading', 'VBG'),\n",
              "  ('edges', 'NNS'),\n",
              "  ('for', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('wings', 'NNS'),\n",
              "  ('and', 'CC'),\n",
              "  ('an', 'DT'),\n",
              "  ('aft', 'JJ'),\n",
              "  ('keel', 'NN'),\n",
              "  ('beam', 'NN'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('Under', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('existing', 'VBG'),\n",
              "  ('contract', 'NN'),\n",
              "  (',', ','),\n",
              "  ('Rockwell', 'NNP'),\n",
              "  ('said', 'VBD'),\n",
              "  (',', ','),\n",
              "  ('it', 'PRP'),\n",
              "  ('has', 'VBZ'),\n",
              "  ('already', 'RB'),\n",
              "  ('delivered', 'VBN'),\n",
              "  ('793', 'CD'),\n",
              "  ('of', 'IN'),\n",
              "  ('the', 'DT'),\n",
              "  ('shipsets', 'NNS'),\n",
              "  ('to', 'TO'),\n",
              "  ('Boeing', 'NNP'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')],\n",
              " [('##', '##'),\n",
              "  ('Rockwell', 'NNP'),\n",
              "  (',', ','),\n",
              "  ('based', 'VBN'),\n",
              "  ('in', 'IN'),\n",
              "  ('El', 'NNP'),\n",
              "  ('Segundo', 'NNP'),\n",
              "  (',', ','),\n",
              "  ('Calif.', 'NNP'),\n",
              "  (',', ','),\n",
              "  ('is', 'VBZ'),\n",
              "  ('an', 'DT'),\n",
              "  ('aerospace', 'NN'),\n",
              "  (',', ','),\n",
              "  ('electronics', 'NNS'),\n",
              "  (',', ','),\n",
              "  ('automotive', 'JJ'),\n",
              "  ('and', 'CC'),\n",
              "  ('graphics', 'NNS'),\n",
              "  ('concern', 'VBP'),\n",
              "  ('.', '.'),\n",
              "  ('&&', '&&')]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5RfuSYcJFaZ"
      },
      "source": [
        "# Generate a dictionary of tags with its corresponding word and word count\n",
        "# eg. {tag: {word1: count(word1, tag), word2: count(word2, tag), ...}, ...}\n",
        "train_tag_dictionary = {}\n",
        "for sentence in training_data_sentences:\n",
        "  for (word, tag) in sentence:\n",
        "    word = word.lower()\n",
        "    try:\n",
        "      try:\n",
        "        # Subsequent appearances of word for the tag\n",
        "        train_tag_dictionary[tag][word] += 1\n",
        "      except:\n",
        "        # First appearance of word for the tag\n",
        "        train_tag_dictionary[tag][word] = 1\n",
        "    except:\n",
        "      # Introducing the word for the tag\n",
        "      train_tag_dictionary[tag] = {word:1}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRzNgA0yJFd_"
      },
      "source": [
        "# Calculate the emission probabilities using dictionary of trained data-\n",
        "# train_tag_dictionary for each tag\n",
        "train_emission_probabilities = {}\n",
        "for tag in train_tag_dictionary.keys():\n",
        "  train_emission_probabilities[tag] = {}\n",
        "  # Total count of the words for the tag\n",
        "  count = sum(train_tag_dictionary[tag].values())\n",
        "  for word in train_tag_dictionary[tag].keys():\n",
        "    # Divide word-count by total count for the tag\n",
        "    train_emission_probabilities[tag][word] = train_tag_dictionary[tag][word]/count"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LAWKVFpJFg-"
      },
      "source": [
        "# Determine the bigrams for the transition probabilities by the bigram tag data\n",
        "# dictionary- tag_bigrams\n",
        "tag_bigrams = {}\n",
        "for sentence in training_data_sentences:\n",
        "  bigram = list(nltk.bigrams(sentence))\n",
        "  for tag1, tag2 in bigram:\n",
        "    try:\n",
        "      try:\n",
        "        # Subsequent appearances of tag2 for the tag1\n",
        "        tag_bigrams[tag1[1]][tag2[1]] += 1\n",
        "      except:\n",
        "        # First appearance of tag2 for the tag1\n",
        "        tag_bigrams[tag1[1]][tag2[1]] = 1\n",
        "    except:\n",
        "      # Introducing the tag2 for the tag1\n",
        "      tag_bigrams[tag1[1]] = {tag2[1]:1}"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhlhhMMpJFkE"
      },
      "source": [
        "# Calculate the tag bigrams' probabilities for transition probabilities  \n",
        "tag_bigram_probabilities = {}\n",
        "for tag1 in tag_bigrams.keys():\n",
        "  tag_bigram_probabilities[tag1] = {}\n",
        "  # Total count of the tag2 for the tag1\n",
        "  count = sum(tag_bigrams[tag1].values())\n",
        "  for tag2 in tag_bigrams[tag1].keys():\n",
        "    # Divide tag2 count by total count for the tag1\n",
        "    tag_bigram_probabilities[tag1][tag2] = tag_bigrams[tag1][tag2]/count"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQUp4XuUJFnN"
      },
      "source": [
        "# Calculate possible tags for each of the word in training and test\n",
        "# dataset (because some words maybe unique to test data)\n",
        "def possible_token_tags(data_sentences):\n",
        "  ''' Return all the possoble tags for each token in the preprocessed\n",
        "  dataset- data_sentences '''\n",
        "  token_tags = {}\n",
        "  for sentence in data_sentences:\n",
        "    for (word, tag) in sentence:\n",
        "      # Change case to lower for consistency\n",
        "      word = word.lower()\n",
        "      try:\n",
        "        # First appearance of tag for the word\n",
        "        if tag not in token_tags[word]:\n",
        "          token_tags[word].append(tag)\n",
        "      except:\n",
        "        # Subsequent appearances of tag for the word\n",
        "        rem_tag = []\n",
        "        rem_tag.append(tag)\n",
        "        token_tags[word] = rem_tag\n",
        "  return token_tags\n",
        "\n",
        "token_tags = {}\n",
        "# Detemine the possible tags of each word in training and testing dataset\n",
        "token_tags = possible_token_tags(training_data_sentences + testing_data_sentences)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NJPzWGLJXYb"
      },
      "source": [
        "# Split the testing dataset into words and tags\n",
        "test_words = []\n",
        "test_tags = []\n",
        "# For each sentence in testing dataset\n",
        "for sentence in testing_data_sentences:\n",
        "  temp_word = []\n",
        "  temp_tag = []\n",
        "  for (word, tag) in sentence:\n",
        "    temp_word.append(word.lower())\n",
        "    temp_tag.append(tag)\n",
        "  # List of words in testing dataset\n",
        "  test_words.append(temp_word)\n",
        "  # List of corresponding tags in the testing dataset\n",
        "  test_tags.append(temp_tag)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHpzegl0JY5b"
      },
      "source": [
        "# The Viterbi Algorithm\n",
        "predicted_tags = []\n",
        "for sentence in test_words:\n",
        "  # viterbi stores the required intermediate values \n",
        "  # eg. viterbi = {state_num : {state1: [previous_best_state, value_of_state], ...}}                \n",
        "  viterbi = {}\n",
        "  for index, state_word in enumerate(sentence):\n",
        "    # For the first word in the sentence\n",
        "    if index == 1:\n",
        "      viterbi[index] = {}\n",
        "      tags = token_tags[state_word]\n",
        "      for tag in tags:\n",
        "        try:\n",
        "          # When the word is present in the training set\n",
        "          viterbi[index][tag] = ['##', tag_bigram_probabilities['##'][tag]*train_emission_probabilities[tag][state]]\n",
        "        except:\n",
        "          # When the  word is unique to testing test i.e. not present in the training set,\n",
        "          # assign a probability of 0.0001\n",
        "          viterbi[index][tag] = ['##', 0.0001]\n",
        "    # For the words other than the first word\n",
        "    if index > 1:\n",
        "      viterbi[index] = {}\n",
        "      # All the previous states\n",
        "      previous_states = list(viterbi[index - 1].keys())\n",
        "      # All the current states\n",
        "      current_states  = token_tags[state_word]\n",
        "      # Calculate the maximum previous viterbi value from the previous states to each\n",
        "      # current states\n",
        "      for cs in current_states:\n",
        "        temp = []\n",
        "        for ps in previous_states:\n",
        "          try:\n",
        "            # When the word is present in the training set\n",
        "            temp.append(viterbi[index - 1][ps][1]*tag_bigram_probabilities[ps][cs]*train_emission_probabilities[cs][state_word])\n",
        "          except:\n",
        "            # When the  word is unique to testing test i.e. not present in the training set,\n",
        "            # assign a probability of 0.0001\n",
        "            temp.append(viterbi[index - 1][ps][1]*0.0001)\n",
        "        # Maximum value for the best previous state\n",
        "        max_temp_index = temp.index(max(temp))\n",
        "        best_ps = previous_states[max_temp_index]\n",
        "        viterbi[index][cs]=[best_ps, max(temp)]\n",
        "  # Backtrack to extract the best possible tags for each word\n",
        "  pred_tags = []\n",
        "  # Total states in the algoritm\n",
        "  total_states = viterbi.keys()\n",
        "  last_state_num = max(total_states)\n",
        "  for bs in range(len(total_states)):\n",
        "    state_num = last_state_num - bs\n",
        "    if state_num == last_state_num:\n",
        "      # For the end of the sentence\n",
        "      pred_tags.append('&&')\n",
        "      pred_tags.append(viterbi[state_num]['&&'][0])\n",
        "    if state_num < last_state_num and state_num > 0:\n",
        "      # Other words in the sentence from the viterbi dictionary\n",
        "      pred_tags.append(viterbi[state_num][pred_tags[len(pred_tags) - 1]][0])\n",
        "  # Reverse the list- pred_tags for correct tags\n",
        "  predicted_tags.append(list(reversed(pred_tags)))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DceXNuYgEZRR"
      },
      "source": [
        "# Create iterable chains from the 2-d lists- test_words, test_tags, predicted_tags\n",
        "separated_test_words = list(chain.from_iterable(test_words))\n",
        "separated_test_tags = list(chain.from_iterable(test_tags))\n",
        "separated_predicted_tags = list(chain.from_iterable(predicted_tags))\n",
        "# Table of word, its corresponding tag and the predicted tag\n",
        "table = []\n",
        "for test_word, test_tag, predicted_tag in zip(separated_test_words, separated_test_tags, separated_predicted_tags):\n",
        "  table.append([test_word, test_tag, predicted_tag])\n",
        "# Dataframe for the table to display given tags and predicted tags\n",
        "dataframe = pd.DataFrame(table, columns=['Word', 'Given Tag', 'Predicted Tag'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfFMVMcuEv2H",
        "cellView": "code",
        "outputId": "6fbe7d60-6d0f-4af7-c0d8-9ee309dbc256",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "# Print the word, its corresponding tag and the predicted tag\n",
        "dataframe"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Given Tag</th>\n",
              "      <th>Predicted Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>##</td>\n",
              "      <td>##</td>\n",
              "      <td>##</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rockwell</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>international</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>corp.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'s</td>\n",
              "      <td>POS</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51336</th>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>TO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51337</th>\n",
              "      <td>mr.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51338</th>\n",
              "      <td>harlow</td>\n",
              "      <td>NNP</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51339</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51340</th>\n",
              "      <td>&amp;&amp;</td>\n",
              "      <td>&amp;&amp;</td>\n",
              "      <td>&amp;&amp;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>51341 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Word Given Tag Predicted Tag\n",
              "0                 ##        ##            ##\n",
              "1           rockwell       NNP           NNP\n",
              "2      international       NNP           NNP\n",
              "3              corp.       NNP           NNP\n",
              "4                 's       POS           POS\n",
              "...              ...       ...           ...\n",
              "51336             to        TO            TO\n",
              "51337            mr.       NNP           NNP\n",
              "51338         harlow       NNP           NNP\n",
              "51339              .         .             .\n",
              "51340             &&        &&            &&\n",
              "\n",
              "[51341 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDuBca3MJcL9",
        "outputId": "c23e588d-61d4-4960-9994-643555d20df6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Calculate the accuracy from the predicted tags\n",
        "true_prediction_count = 0 \n",
        "false_prediction_count = 0\n",
        "for index, test_sentence in enumerate(test_tags):\n",
        "  predicted = predicted_tags[index]\n",
        "  for inner_index, given in enumerate(test_sentence):\n",
        "    # Increment if given tag and predicted tag match\n",
        "    if given == predicted[inner_index]:\n",
        "      true_prediction_count += 1\n",
        "    else:\n",
        "      false_prediction_count += 1\n",
        "# Accuracy and Loss calculations\n",
        "accuracy = (true_prediction_count/(true_prediction_count+false_prediction_count))*100\n",
        "loss = (false_prediction_count/(true_prediction_count+false_prediction_count))*100\n",
        "print('Accuracy: {0:.2f}%'.format(accuracy))\n",
        "print('Loss: {0:.2f}%'.format(loss))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 96.53%\n",
            "Loss: 3.47%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}